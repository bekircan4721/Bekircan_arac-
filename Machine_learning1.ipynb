{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzWuN0zBh5m6AXJc1w0uMI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekircan4721/Bekircan_arac-/blob/main/Machine_learning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIXGO0kmsIsZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import shapiro, anderson, kstest, normaltest, zscore, probplot, pearsonr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.utils import resample\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "data_shark = pd.read_csv(\"https://raw.githubusercontent.com/bekircan4721/Bekircan_arac-/main/attacks.csv\", encoding=\"unicode_escape\")\n",
        "data_temperature = pd.read_table(\"https://www.ncei.noaa.gov/data/oceans/woa/DATA_ANALYSIS/3M_HEAT_CONTENT/DATA/basin/pentad/pent_h22-w0-2000m.dat\", delim_whitespace=True)\n",
        "\n",
        "# filtering on year\n",
        "data_shark = data_shark[data_shark[\"Year\"].notnull()]\n",
        "data_shark[\"Year\"] = data_shark[\"Year\"].astype(int)\n",
        "\n",
        "# merging temperature with year\n",
        "temperature_by_year = data_temperature[[\"YEAR\", \"WO\"]].copy()\n",
        "temperature_by_year.columns = [\"Year\", \"Ocean_Temperature\"]\n",
        "temperature_by_year[\"Year\"] = temperature_by_year[\"Year\"].round().astype(int)\n",
        "\n",
        "# yearly attack_count\n",
        "shark_by_year = data_shark.groupby(\"Year\").size().reset_index(name=\"Attack_Count\")\n",
        "\n",
        "# merging data's on year feature\n",
        "merged = pd.merge(shark_by_year, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "merged = merged.dropna(subset=[\"Ocean_Temperature\"])\n",
        "\n",
        "# taking log in order to obtain normalized distrubution\n",
        "merged[\"Attack_Count_log\"] = np.log1p(merged[\"Attack_Count\"])\n",
        "\n",
        "# graphic parts\n",
        "\n",
        "# Histplot\n",
        "for col in [\"Attack_Count\", \"Ocean_Temperature\"]:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(merged[col], kde=True)\n",
        "    plt.title(f\"{col} - Histogram & KDE\")\n",
        "    plt.show()\n",
        "\n",
        "# Histogram ve KDE\n",
        "for col in [\"Attack_Count_log\", \"Ocean_Temperature\"]:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(merged[col], kde=True)\n",
        "    plt.title(f\"{col} - Histogram & KDE\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# checking if distributions have normal distribution\n",
        "for col in [\"Attack_Count\", \"Ocean_Temperature\"]:\n",
        "    standardized = zscore(merged[col])\n",
        "    stat, p = kstest(standardized, 'norm')\n",
        "    print(f\"K-S Test(without normalization) - {col} (z-score): stat={stat:.4f}, p={p:.4f}\")\n",
        "\n",
        "\n",
        "# k-s test again, now we will check that taking logarithm of attack_count works for normalization\n",
        "for col in [\"Attack_Count_log\", \"Ocean_Temperature\"]:\n",
        "    standardized = zscore(merged[col])\n",
        "    stat, p = kstest(standardized, 'norm')\n",
        "    print(f\"K-S Test(Logarithm for attack_count) - {col} (z-score): stat={stat:.4f}, p={p:.4f}\")\n",
        "\n",
        "# linear regression year based\n",
        "\n",
        "X = merged[[\"Ocean_Temperature\"]]\n",
        "y = merged[\"Attack_Count_log\"]\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "print(f\"Linear Regression R^^2: {r2_score(y, y_pred):.4f}\")\n",
        "print(f\"Linear Regression MSE: {mean_squared_error(y, y_pred):.4f}\")\n",
        "\n",
        "# Bootstrap sampling lists\n",
        "r2_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "X_vals = X.values\n",
        "y_vals = y.values\n",
        "n_iterations = 1000\n",
        "n_size = len(merged)\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X_vals, y_vals, n_samples=n_size, replace=True)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_resampled, y_resampled)\n",
        "    y_pred = model.predict(X_resampled)\n",
        "    r2_scores.append(r2_score(y_resampled, y_pred))\n",
        "    mse_scores.append(mean_squared_error(y_resampled, y_pred))\n",
        "\n",
        "print(f\"R^^2 mean: {np.mean(r2_scores):.4f}, 95% CI: ({np.percentile(r2_scores, 2.5):.4f}, {np.percentile(r2_scores, 97.5):.4f})\")\n",
        "print(f\"MSE mean: {np.mean(mse_scores):.4f}, 95% CI: ({np.percentile(mse_scores, 2.5):.4f}, {np.percentile(mse_scores, 97.5):.4f})\")\n",
        "\n",
        "# random forest model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(f\"Random Forest R^^2: {r2_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Random Forest MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
        "\n",
        "# adding feature part\n",
        "\n",
        "shark_by_year_country = data_shark.groupby([\"Year\", \"Country\"]).size().reset_index(name=\"Attack_Count\")\n",
        "df = pd.merge(shark_by_year_country, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "df = df.dropna(subset=[\"Ocean_Temperature\"])\n",
        "df[\"Attack_Count_log\"] = np.log1p(df[\"Attack_Count\"])\n",
        "\n",
        "# One-hot encode Country because this feature is discrete\n",
        "df_encoded = pd.get_dummies(df, columns=[\"Country\"], drop_first=True)\n",
        "features = df_encoded.columns.difference([\"Attack_Count\", \"Attack_Count_log\"])\n",
        "\n",
        "X_feat = df_encoded[features]\n",
        "y_feat = df_encoded[\"Attack_Count_log\"]\n",
        "\n",
        "X_train_feat, X_test_feat, y_train_feat, y_test_feat = train_test_split(X_feat, y_feat, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# these lists will hold the values of bootstrap samples\n",
        "r2_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "X_vals = X_feat.values\n",
        "y_vals = y_feat.values\n",
        "n_size = len(df_encoded)\n",
        "n_iterations = 1000\n",
        "\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X_vals, y_vals, n_samples=n_size, replace=True)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_resampled, y_resampled)\n",
        "    y_pred = model.predict(X_resampled)\n",
        "    r2_scores.append(r2_score(y_resampled, y_pred))\n",
        "    mse_scores.append(mean_squared_error(y_resampled, y_pred))\n",
        "\n",
        "print(f\"After feature adding :R^^2(mean){np.mean(r2_scores):.4f}, 95% CI: ({np.percentile(r2_scores, 2.5):.4f}, {np.percentile(r2_scores, 97.5):.4f})\")\n",
        "print(f\"After feature adding: MSE(mean): {np.mean(mse_scores):.4f}, 95% CI: ({np.percentile(mse_scores, 2.5):.4f}, {np.percentile(mse_scores, 97.5):.4f})\")\n",
        "\n",
        "\n",
        "# Linear Regression after adding feature\n",
        "model_feat = LinearRegression()\n",
        "model_feat.fit(X_train_feat, y_train_feat)\n",
        "y_pred_feat = model_feat.predict(X_test_feat)\n",
        "\n",
        "print(f\"Linear Regression R^^2 (with features): {r2_score(y_test_feat, y_pred_feat):.4f}\")\n",
        "print(f\"Linear Regression MSE (with features): {mean_squared_error(y_test_feat, y_pred_feat):.4f}\")\n",
        "\n",
        "coefs = pd.Series(model_feat.coef_, index=features).sort_values(key=abs, ascending=False)\n",
        "print(\"\\nBest 10 feature for model (using Linear Regression)\")\n",
        "print(coefs.head(10))\n",
        "\n",
        "# Random Forest modeli (features ile)\n",
        "random_forest_features = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_features.fit(X_train_feat, y_train_feat)\n",
        "predicted_random_forest_values = random_forest_features.predict(X_test_feat)\n",
        "\n",
        "print(f\"\\nRandom Forest R^^2 (with features): {r2_score(y_test_feat, predicted_random_forest_values):.4f}\")\n",
        "print(f\"Random Forest MSE (with features): {mean_squared_error(y_test_feat, predicted_random_forest_values):.4f}\")\n",
        "\n",
        "feat_importances = pd.Series(random_forest_features.feature_importances_, index=features).sort_values(ascending=False)\n",
        "print(\"\\nBest 10 feature for model (Using Random Forest):\")\n",
        "print(feat_importances.head(10))\n",
        "\n",
        "\n"
      ]
    }
  ]
}