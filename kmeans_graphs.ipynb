{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1I3-l1oT1MDJLBeqbwgFrjyFfNBDBhhZS",
      "authorship_tag": "ABX9TyNzZWxpad1NYhLIfLGLWA2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekircan4721/Bekircan_arac-/blob/main/kmeans_graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "data_shark = pd.read_csv(\"https://raw.githubusercontent.com/bekircan4721/Bekircan_arac-/main/attacks.csv\", encoding=\"unicode_escape\")\n",
        "data_temperature = pd.read_table(\"https://www.ncei.noaa.gov/data/oceans/woa/DATA_ANALYSIS/3M_HEAT_CONTENT/DATA/basin/pentad/pent_h22-w0-2000m.dat\", delim_whitespace=True)\n",
        "\n",
        "\n",
        "data_shark = data_shark[data_shark[\"Year\"].notnull()]\n",
        "data_shark[\"Year\"] = data_shark[\"Year\"].astype(int)\n",
        "\n",
        "\n",
        "temperature_by_year = data_temperature[[\"YEAR\", \"WO\"]].copy()\n",
        "temperature_by_year.columns = [\"Year\", \"Ocean_Temperature\"]\n",
        "temperature_by_year[\"Year\"] = temperature_by_year[\"Year\"].round().astype(int)\n",
        "\n",
        "\n",
        "shark_by_year = data_shark.groupby(\"Year\").size().reset_index(name=\"Attack_Count\")\n",
        "\n",
        "\n",
        "merged = pd.merge(shark_by_year, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "merged = merged.dropna(subset=[\"Ocean_Temperature\"])\n",
        "\n",
        "# normalizing distribution -> performing machine learning models\n",
        "merged[\"Attack_Count_log\"] = np.log1p(merged[\"Attack_Count\"])\n",
        "\n",
        "# adding feature (country)\n",
        "\n",
        "shark_by_year_country = data_shark.groupby([\"Year\", \"Country\"]).size().reset_index(name=\"Attack_Count\")\n",
        "df = pd.merge(shark_by_year_country, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "df = df.dropna(subset=[\"Ocean_Temperature\"])\n",
        "df[\"Attack_Count_log\"] = np.log1p(df[\"Attack_Count\"])\n",
        "\n",
        "# since country is not numerical, we need to change its form by using one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=[\"Country\"], drop_first=True)\n",
        "features = df_encoded.columns.difference([\"Attack_Count\", \"Attack_Count_log\"])\n",
        "\n",
        "X_feat = df_encoded[features]\n",
        "y_feat = df_encoded[\"Attack_Count_log\"]\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "reduced_features = pca.fit_transform(df_encoded[features])\n",
        "\n",
        "# K means clustering, Hard clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "# note that features is defined in feature adding part.\n",
        "cluster_labels = kmeans.fit_predict(df_encoded[features])\n",
        "\n",
        "# adding the result of cluster to the encoded data, so we can use the data for ML models\n",
        "df_encoded['cluster'] = cluster_labels\n",
        "\n",
        "# one hot encoding the clustered part, so we can perform Ml models\n",
        "cluster_encoded = pd.get_dummies(df_encoded['cluster'], prefix='cluster')\n",
        "\n",
        "# extending features part, because we got a new column clustered part,\n",
        "# we are searching whether this will improve our model\n",
        "X_with_cluster = pd.concat([df_encoded[features], cluster_encoded], axis=1)\n",
        "y = df_encoded['Attack_Count_log']\n",
        "\n",
        "# training model\n",
        "# note that, X_with_cluster is our features, y is our target feature.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_with_cluster, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# performing random forest model after clustering modification.\n",
        "random_forest_after_k_means = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_after_k_means.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "k_means_predictions = random_forest_after_k_means.predict(X_test)\n",
        "print(f\"Hard Clustering + Random Forest R^^s2: {r2_score(y_test, k_means_predictions):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, k_means_predictions):.4f}\")\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(df_encoded[features])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=kmeans_labels, s=50)\n",
        "plt.title(\"K-Means Clustering\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Soft clustering\n",
        "# I will use GaussianMixture to obtain soft clustering model\n",
        "gassuian_model = GaussianMixture(n_components=5, random_state=42)\n",
        "gassuian_model.fit(df_encoded[features])\n",
        "cluster_probs = gassuian_model.predict_proba(df_encoded[features])\n",
        "\n",
        "# transforming clusters into a dataframe, so we can add this to our encoded dataframe\n",
        "cluster_probs_df = pd.DataFrame(cluster_probs, columns=[f'cluster_{i}' for i in range(5)], index=df_encoded.index)\n",
        "\n",
        "# features\n",
        "X_with_soft_cluster = pd.concat([df_encoded[features], cluster_probs_df], axis=1)\n",
        "y = df_encoded['Attack_Count_log']\n",
        "\n",
        "# again note that, X_with soft cluster is concatened features that includes soft clustering model's result\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_with_soft_cluster, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# evaluating the performance difference after soft clustering\n",
        "random_forest_after_soft = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_after_soft.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions_soft = random_forest_after_soft.predict(X_test)\n",
        "print(f\"Soft Clustering + Random Forest R^^2: {r2_score(y_test, predictions_soft):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, predictions_soft):.4f}\")\n",
        "\n",
        "visual_gaussian = GaussianMixture(n_components=5, random_state=42)\n",
        "gaussian_labels = visual_gaussian.fit_predict(df_encoded[features])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=gaussian_labels, cmap='plasma', s=50)\n",
        "plt.title(\"Gaussian Mixture (Soft Clustering)\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "# 1. Flat clustering\n",
        "# I will use Agglomerative method to flat clustering\n",
        "agglomerative_method = AgglomerativeClustering(n_clusters=5)\n",
        "cluster_labels = agglomerative_method.fit_predict(df_encoded[features])\n",
        "\n",
        "# modifying encoded dataframe with the result of agglomerative method's result\n",
        "# note that I only changed cluster feature, not adding a new column(past modifications do not change my model)\n",
        "df_encoded['cluster'] = cluster_labels\n",
        "\n",
        "# since cluster is categorical value, I need one-hot encoding\n",
        "cluster_encoded = pd.get_dummies(df_encoded['cluster'], prefix='cluster')\n",
        "\n",
        "# extending features that we search\n",
        "X_with_cluster = pd.concat([df_encoded[features], cluster_encoded], axis=1)\n",
        "y = df_encoded['Attack_Count_log']\n",
        "\n",
        "# again note thaat X_with cluster contains the result of flat clustering\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_with_cluster, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# re-evaluating the random forest model's performance after flat clustering\n",
        "flat_random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "flat_random_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "flat_predictions = flat_random_forest.predict(X_test)\n",
        "print(f\"Flat Clustering + Random Forest R^^2: {r2_score(y_test, flat_predictions):.4f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, flat_predictions):.4f}\")\n",
        "\n",
        "visual_agglo = AgglomerativeClustering(n_clusters=5)\n",
        "agglo_labels = visual_agglo.fit_predict(df_encoded[features])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=agglo_labels, cmap='coolwarm', s=50)\n",
        "plt.title(\"Agglomerative Clustering\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "id": "2c7Isu1fOn1K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}