{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekircan4721/Bekircan_arac-/blob/main/Visualizing_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "data_shark = pd.read_csv(\"https://raw.githubusercontent.com/bekircan4721/Bekircan_arac-/main/attacks.csv\", encoding=\"unicode_escape\")\n",
        "data_temperature = pd.read_table(\"https://www.ncei.noaa.gov/data/oceans/woa/DATA_ANALYSIS/3M_HEAT_CONTENT/DATA/basin/pentad/pent_h22-w0-2000m.dat\", delim_whitespace=True)\n",
        "\n",
        "\n",
        "data_shark = data_shark[data_shark[\"Year\"].notnull()]\n",
        "data_shark[\"Year\"] = data_shark[\"Year\"].astype(int)\n",
        "\n",
        "\n",
        "temperature_by_year = data_temperature[[\"YEAR\", \"WO\"]].copy()\n",
        "temperature_by_year.columns = [\"Year\", \"Ocean_Temperature\"]\n",
        "temperature_by_year[\"Year\"] = temperature_by_year[\"Year\"].round().astype(int)\n",
        "\n",
        "\n",
        "shark_by_year = data_shark.groupby(\"Year\").size().reset_index(name=\"Attack_Count\")\n",
        "\n",
        "\n",
        "merged = pd.merge(shark_by_year, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "merged = merged.dropna(subset=[\"Ocean_Temperature\"])\n",
        "\n",
        "# normalizing distribution -> performing machine learning models\n",
        "merged[\"Attack_Count_log\"] = np.log1p(merged[\"Attack_Count\"])\n",
        "\n",
        "# adding feature (country)\n",
        "\n",
        "shark_by_year_country = data_shark.groupby([\"Year\", \"Country\"]).size().reset_index(name=\"Attack_Count\")\n",
        "df = pd.merge(shark_by_year_country, temperature_by_year, on=\"Year\", how=\"left\")\n",
        "df = df.dropna(subset=[\"Ocean_Temperature\"])\n",
        "df[\"Attack_Count_log\"] = np.log1p(df[\"Attack_Count\"])\n",
        "\n",
        "# since country is not numerical, we need to change its form by using one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=[\"Country\"], drop_first=True)\n",
        "features = df_encoded.columns.difference([\"Attack_Count\", \"Attack_Count_log\"])\n",
        "\n",
        "X_feat = df_encoded[features]\n",
        "y_feat = df_encoded[\"Attack_Count_log\"]\n",
        "\n",
        "# generating correlation matrix\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# visualizing matrix\n",
        "plt.figure(figsize=(20, 15))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_feat, y_feat, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions_of_linear_model = linear_model.predict(X_test)\n",
        "\n",
        "# I added jitter to decrease density points\n",
        "jitter_strength = 0.03\n",
        "y_test_jittered = y_test + np.random.normal(0, jitter_strength, size=len(y_test))\n",
        "y_pred_jittered = predictions_of_linear_model + np.random.normal(0, jitter_strength, size=len(predictions_of_linear_model))\n",
        "\n",
        "# visual generating\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(y_test_jittered, y_pred_jittered, alpha=0.4, s=60)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='y = x')\n",
        "\n",
        "plt.xlabel(\"Real Attack Count\")\n",
        "plt.ylabel(\"Predicted  Attack_Count_log\")\n",
        "plt.title(\"Linear Regression: Real vs Predicted (Attack_Count_log)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H_Tzy1ihKKoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}